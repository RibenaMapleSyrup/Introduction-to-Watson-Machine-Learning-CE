{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIGGS example using IBM PowerAI Snap ML\n",
    "\n",
    "In this example we will train a Logistic Regression model on the HIGGS dataset, using both scikit-learn and snap-ml-local.\n",
    "\n",
    "The HIGGS dataset is avaliable in the UCI machine learning repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluating a Logistic Regression Model using CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and decompress the data from the LIBSVM repository\n",
    "# This may take some time! \n",
    "!mkdir -p data; cd data; wget https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/HIGGS.bz2; bunzip2 HIGGS.bz2; cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "defaultPath = \".\"\n",
    "\n",
    "X,y = load_svmlight_file(defaultPath + \"/data/HIGGS\")\n",
    "\n",
    "# Make the train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Convert to numpy ararys\n",
    "import numpy as np\n",
    "X_train = np.array(X_train.todense())\n",
    "X_test  = np.array(X_test.todense())\n",
    "\n",
    "# Normalize the training data\n",
    "from sklearn.preprocessing import normalize\n",
    "X_train = normalize(X_train, axis=1, norm='l1')\n",
    "X_test  = normalize(X_test,  axis=1, norm='l1')\n",
    "\n",
    "# Save the dense matrices\n",
    "np.save(defaultPath + \"/data/HIGGS.X_train\", X_train)\n",
    "np.save(defaultPath + \"/data/HIGGS.X_test\",  X_test)\n",
    "\n",
    "# Save the labels\n",
    "np.save(defaultPath + \"/data/HIGGS.y_train\", y_train)\n",
    "np.save(defaultPath + \"/data/HIGGS.y_test\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data load time (s):  11.59\n"
     ]
    }
   ],
   "source": [
    "# Training and Evaluating a Logistic Regression Model using CPU\n",
    "from scipy import sparse\n",
    "\n",
    "# Load the data\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "defaultPath = \".\"\n",
    "\n",
    "t0 = time.time()\n",
    "X_train = np.load(defaultPath + \"/data/HIGGS.X_train.npy\")\n",
    "X_test  = np.load(defaultPath + \"/data/HIGGS.X_test.npy\")\n",
    "y_train = np.load(defaultPath + \"/data/HIGGS.y_train.npy\")\n",
    "y_test  = np.load(defaultPath + \"/data/HIGGS.y_test.npy\")\n",
    "print(\"Data load time (s):  {0:.2f}\".format(time.time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Training will run in multi-threaded mode on CPU.\n",
      "[snap.ml] Training time (s):  6.99\n",
      "[snap.ml] Logarithmic loss:   0.6374\n",
      "[sklearn] Training time (s):  76.45\n",
      "[sklearn] Logarithmic loss:   0.6374\n"
     ]
    }
   ],
   "source": [
    "# Import the LogisticRegression from snap.ml\n",
    "from pai4sk import LogisticRegression\n",
    "lr = LogisticRegression(use_gpu=False, max_iter=15, dual=True, num_threads=32, device_ids=[])\n",
    "\n",
    "# Training\n",
    "t0 = time.time()\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"[snap.ml] Training time (s):  {0:.2f}\".format(time.time()-t0))\n",
    "\n",
    "# Inference\n",
    "proba_test = lr.predict_proba(X_test)\n",
    "\n",
    "# Evaluate log-loss on test set\n",
    "from sklearn.metrics import log_loss\n",
    "logloss_snap = log_loss(y_test, proba_test)\n",
    "print(\"[snap.ml] Logarithmic loss:   {0:.4f}\".format(logloss_snap))\n",
    "\n",
    "# Import the LogisticRegression from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(fit_intercept=False, dual=True, solver=\"liblinear\")\n",
    "\n",
    "# Training time\n",
    "t0 = time.time()\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"[sklearn] Training time (s):  {0:.2f}\".format(time.time()-t0))\n",
    "\n",
    "# Inference\n",
    "proba_test = lr.predict_proba(X_test)\n",
    "\n",
    "# Evaluate log-loss on test set\n",
    "logloss_sklearn = log_loss(y_test, proba_test)\n",
    "print(\"[sklearn] Logarithmic loss:   {0:.4f}\".format(logloss_sklearn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
