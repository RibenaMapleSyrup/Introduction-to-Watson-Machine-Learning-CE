{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with SnapBoost and XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will illustrate machine learning classification using two gradient boosting frameworks; XGBoost and SnapBoost. Many thanks to Tom Parnell and IBM Research Zurich who wrote the original notebook from which I adapted this workshop-friendly copy. \n",
    "We will compare the generalization capability of both frameworks. More on generalization later...\n",
    "Gradient boosting machines (GBMs) can be particularly effective when working with tabular data, especially for large and complex datasets. This notebook embraces choice; you can choose one of 9 binary classification datasets from [OpenML](https://www.openml.org/) to explore and then train your models with.\n",
    "\n",
    "## What is gradient boosting?\n",
    "\n",
    "Lets start with 'boosting'. Boosting is a method for creating an ensemble of weak simple prediction models (typically decision trees) that when added together create a strong model that fits more accurately to our dataset. \n",
    "\n",
    "Now what about gradient boosting?\n",
    "\n",
    "Gradient boosting involves creating our ensemble of weaker models in a sequential way where each weak models are added to our stronger composite model one after the other to nudge our composite model into being better. This approach of sequentially adding models is benificial because each subsequent model can learn from the mistakes of the previous model. \n",
    "\n",
    "As an example, we start by fitting an initial model (e.g. a tree or linear regression) to our data. Then a second model is built that focuses on accurately predicting the cases where the first model performs poorly (observations with the highest error). The combination of these two models is expected to be better than either model alone. Then you repeat this process of boosting many times.  Each successive model attempts to correct for the shortcomings of the combined boosted ensemble of all previous models. \n",
    "\n",
    "One caveat here is we need to be careful about overfitting so we need to be clear on our stopping criteria to stop boosting! You also need to tune the GBM to get a good model unlike Random Forest. To tune the hyper-parameters some understanding of underlying maths is required which is beyond the scope of today, however for some fantastic explanations to help build intuition around gradient boosting, I would recommend this article: https://explained.ai/gradient-boosting/index.html\n",
    "\n",
    "For this demo we'll do the following:\n",
    "\n",
    "* Choose a dataset\n",
    "* Explore our data\n",
    "* Prepare the data\n",
    "* Define inner cross validation for hyper-parameter tuning \n",
    "* Define outer cross validation to estimate generalisation \n",
    "* Train our model\n",
    "* Analyse model performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation of required dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by importing all necessary modules and functions. We also print out the version of XGBoost and pai4sk we are using to ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openml in /opt/anaconda/envs/wmlce/lib/python3.7/site-packages (0.10.2)\n",
      "Requirement already satisfied: liac-arff>=2.4.0 in /opt/anaconda/envs/wmlce/lib/python3.7/site-packages (from openml) (2.5.0)\n",
      "Requirement already satisfied: xmltodict in /opt/anaconda/envs/wmlce/lib/python3.7/site-packages (from openml) (0.12.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/anaconda/envs/wmlce/lib/python3.7/site-packages (from openml) (2.8.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda/envs/wmlce/lib/python3.7/site-packages (from openml) (2.22.0)\n",
      "Requirement already satisfied: numpy>=1.6.2 in /opt/anaconda/envs/wmlce/lib/python3.7/site-packages (from openml) (1.17.4)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /opt/anaconda/envs/wmlce/lib/python3.7/site-packages (from openml) (0.22.1)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /opt/anaconda/envs/wmlce/lib/python3.7/site-packages (from openml) (1.3.1)\n",
      "Requirement already satisfied: pandas>=0.19.2 in /opt/anaconda/envs/wmlce/lib/python3.7/site-packages (from openml) (0.24.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda/envs/wmlce/lib/python3.7/site-packages (from python-dateutil->openml) (1.13.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda/envs/wmlce/lib/python3.7/site-packages (from requests->openml) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda/envs/wmlce/lib/python3.7/site-packages (from requests->openml) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda/envs/wmlce/lib/python3.7/site-packages (from requests->openml) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda/envs/wmlce/lib/python3.7/site-packages (from requests->openml) (2020.6.20)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda/envs/wmlce/lib/python3.7/site-packages (from scikit-learn>=0.18->openml) (0.13.2)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/anaconda/envs/wmlce/lib/python3.7/site-packages (from pandas>=0.19.2->openml) (2019.3)\n",
      "Using XGBoost version: 0.90\n",
      "Using pai4sk version:  1.6.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install openml\n",
    "\n",
    "import openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pai4sk\n",
    "import psutil\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Process, Queue\n",
    "from pai4sk.metrics import log_loss\n",
    "from pai4sk.preprocessing import LabelEncoder\n",
    "from pai4sk.model_selection import StratifiedKFold\n",
    "print(\"Using XGBoost version: %s\" % (xgb.__version__))\n",
    "print(\"Using pai4sk version:  %s\" % (pai4sk.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of datasets from OpenML we can use. \n",
    "Select the dataset from the corresponding number to use it:\n",
    "\n",
    "4154 - Credit Card Subset  \n",
    "\n",
    "1471 - EEG measurement with the Emotiv EEG Neuroheadset \n",
    "\n",
    "4534 - Phishing Websites\n",
    "\n",
    "734 - control data from F16 aircraft\n",
    "\n",
    "1046 - Mozilla data\n",
    "\n",
    "1019 - pen digits\n",
    "\n",
    "959 - nursery admissions\n",
    "\n",
    "977 - Letter Image Recognition Data\n",
    "\n",
    "846 - Aircraft control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change dataset_id to the above id of the dataset you want to explore.\n",
    "dataset_id = 734\n",
    "dataset = openml.datasets.get_dataset(dataset_id)\n",
    "\n",
    "X, y, categorical_indicator, ft_names = dataset.get_data(target=dataset.default_target_attribute)\n",
    "A = dataset.get_data(target=dataset.default_target_attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive and Negative Class Distribution\n",
    "\n",
    "We know our labels can either be P or N so lets explore the relative frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    7922\n",
       "P    5828\n",
       "Name: binaryClass, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical data class skew\n",
    "\n",
    "If our dataset has numeric columns, we can average those values across both our label categories and check for any class skew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>climbRate</th>\n",
       "      <th>Sgz</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>curPitch</th>\n",
       "      <th>curRoll</th>\n",
       "      <th>absRoll</th>\n",
       "      <th>diffClb</th>\n",
       "      <th>diffRollRate</th>\n",
       "      <th>diffDiffClb</th>\n",
       "      <th>...</th>\n",
       "      <th>diffSeTime7</th>\n",
       "      <th>diffSeTime8</th>\n",
       "      <th>diffSeTime9</th>\n",
       "      <th>diffSeTime10</th>\n",
       "      <th>diffSeTime11</th>\n",
       "      <th>diffSeTime12</th>\n",
       "      <th>diffSeTime13</th>\n",
       "      <th>diffSeTime14</th>\n",
       "      <th>alpha</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>8.929822</td>\n",
       "      <td>-14.322752</td>\n",
       "      <td>0.103756</td>\n",
       "      <td>0.107519</td>\n",
       "      <td>0.703116</td>\n",
       "      <td>0.157756</td>\n",
       "      <td>-14.092485</td>\n",
       "      <td>-1.660604</td>\n",
       "      <td>-0.001451</td>\n",
       "      <td>-0.123610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>-2.059025e-06</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-1.715854e-06</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>-1.372684e-06</td>\n",
       "      <td>0.719303</td>\n",
       "      <td>0.025514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>-25.839308</td>\n",
       "      <td>-11.331861</td>\n",
       "      <td>-0.066026</td>\n",
       "      <td>0.027112</td>\n",
       "      <td>0.575184</td>\n",
       "      <td>-0.008748</td>\n",
       "      <td>-8.794749</td>\n",
       "      <td>-0.394724</td>\n",
       "      <td>-0.000587</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>6.311537e-07</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-3.786922e-07</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-1.262307e-07</td>\n",
       "      <td>0.553105</td>\n",
       "      <td>0.019424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   climbRate        Sgz         p         q  curPitch   curRoll    absRoll  \\\n",
       "y                                                                            \n",
       "P   8.929822 -14.322752  0.103756  0.107519  0.703116  0.157756 -14.092485   \n",
       "N -25.839308 -11.331861 -0.066026  0.027112  0.575184 -0.008748  -8.794749   \n",
       "\n",
       "    diffClb  diffRollRate  diffDiffClb  ...  diffSeTime7  diffSeTime8  \\\n",
       "y                                       ...                             \n",
       "P -1.660604     -0.001451    -0.123610  ...    -0.000071          0.0   \n",
       "N -0.394724     -0.000587     0.000151  ...    -0.000101          0.0   \n",
       "\n",
       "   diffSeTime9  diffSeTime10  diffSeTime11  diffSeTime12  diffSeTime13  \\\n",
       "y                                                                        \n",
       "P    -0.000088 -2.059025e-06     -0.000084 -1.715854e-06     -0.000081   \n",
       "N    -0.000112  6.311537e-07     -0.000114 -3.786922e-07     -0.000109   \n",
       "\n",
       "   diffSeTime14     alpha        Se  \n",
       "y                                    \n",
       "P -1.372684e-06  0.719303  0.025514  \n",
       "N -1.262307e-07  0.553105  0.019424  \n",
       "\n",
       "[2 rows x 40 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def skewCheck (X,y):\n",
    "    df = X._get_numeric_data()\n",
    "    if df.empty:\n",
    "        print(\"Dataframe contains no numeric data.\")\n",
    "    else: \n",
    "        df['y'] = y\n",
    "        return df.groupby('y').mean()\n",
    "    \n",
    "skewCheck(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset\n",
    "\n",
    "Since ML algorithms works with numbers, we would like to map string or categorical inputs to integers. Any categorical features are encoded using a label encoder, and all labels are encoded so that they either take value 0 or 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode our data and then save as a numpy array\n",
    "for (ft_ind, ft_name) in enumerate(ft_names):\n",
    "        if categorical_indicator[ft_ind]:\n",
    "            X[ft_name] = LabelEncoder().fit_transform(X[ft_name])\n",
    "\n",
    "X = X.values.astype(np.float64)\n",
    "\n",
    "# encode labels to 0,1\n",
    "y = np.array(y)\n",
    "labels = sorted(list(set(y)))\n",
    "y[y == labels[0]] = 0\n",
    "y[y == labels[1]] = 1\n",
    "y = y.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training <a name=\"model_training\"></a>\n",
    "\n",
    "We have transformed our data and are now ready to build our models, XGBoost and SnapBoost:\n",
    "\n",
    "\n",
    "### What is XGBoost?\n",
    "\n",
    "XGBoost is extreme gradient boosting algorithm based on trees and tends to perform very good out of the box compare to other ML algorithms.\n",
    "XGBoost is popular amongt data-scientist and one of the most common ML algorithms used in [Kaggle](https://www.kaggle.com/) Competitions.\n",
    "\n",
    "## What is SnapBoost?\n",
    "\n",
    "SnapBoost is a new boosting algorithm developed by IBM Research in Zurich. It is different to popular boosting algorithms such as XGBoost, CATboost in that rather than our ensemble being made up of models with the same architecture (ie all decision trees with the same depth), SnapBoost builds an ensemble of different architectures (trees of different depth, regression algorithms) to approximate a wider class of functions. Therefore SnapBoost inolves heterogenous gradient boosting, rather than homogeneous. There are some other unique features like early stopping if our model ceases to improve etc. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define a function that trains an XGBoost model, for a given set of hyper-parameters, on the training set and then evaluates the trained model on the test set. The evaluation metric used in this demo is the logistic loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_xgb(X_train, y_train, X_test, y_test, params):\n",
    "    \"\"\" Train and evaluate an XGBoost model for a given set of parameters\n",
    "    \n",
    "    Args:\n",
    "        X_train (np.ndarray): Training feature matrix\n",
    "        y_train (np.ndarray): Training labels\n",
    "        X_test (np.ndarray): Test feature matrix\n",
    "        y_test (np.ndarray): Test labels\n",
    "        params (dict): Hyper-parameters of XGBoost\n",
    "\n",
    "    Returns:\n",
    "        score (float): Logistic loss of the trained model evaluated on the test set\n",
    "        \n",
    "    \"\"\"\n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    dtest = xgb.DMatrix(X_test, y_test)\n",
    "    xgb_params = params.copy()\n",
    "    num_round = xgb_params['num_round']\n",
    "    xgb_params.pop('num_round')\n",
    "    bst = xgb.train(xgb_params, dtrain, num_boost_round=num_round)\n",
    "    z_test = bst.predict(dtest)\n",
    "    score = log_loss(y_test, z_test.astype(np.float64))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a function that does the same, but for SnapBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_snap(X_train, y_train, X_test, y_test, params):\n",
    "    \"\"\" Train and evaluate a SnapBoost model for a given set of parameters\n",
    "    \n",
    "    Args:\n",
    "        X_train (np.ndarray): Training feature matrix\n",
    "        y_train (np.ndarray): Training labels\n",
    "        X_test (np.ndarray): Test feature matrix\n",
    "        y_test (np.ndarray): Test labels\n",
    "        params (dict): Hyper-parameters of SnapBoost\n",
    "\n",
    "    Returns:\n",
    "        score (float): Logistic loss of the trained model evaluated on the test set\n",
    "        \n",
    "    \"\"\"\n",
    "    bst = pai4sk.BoostingMachine(**params)\n",
    "    bst.fit(X_train, y_train)\n",
    "    z_test = bst.predict_proba(X_test)[:,1]\n",
    "    score = log_loss(y_test, z_test.astype(np.float64))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't yet talked about splitting our data into test and train...\n",
    "\n",
    "Since both models have a lot of different hyper-parameters, it is very important that cross-validation (CV) is performed to tune the models to achieve their maximum potential. \n",
    "\n",
    "Hold the phone, what is cross validation? \n",
    "\n",
    "Well, there are shortcomings to splitting our data into fixed train, test and validation sets and using the same validation set to evaluate and holding back test till train is complete. The performance of our model will be dependent on the specific subsets of data we choose for training and validation. It could be that if we chose a different subset of the data for training and validation that model performance could be quite different. In this case it would be even better if we could split our training and validation sets multiple times with each time being on a different subset of the data, evaluate our model each time and look at the average performance of the models trained over these multiple evaluations. Enter k-fold cross validation ...  \n",
    "\n",
    "So how does k-fold cross validation work in practice? \n",
    "\n",
    "1. Split your data into K ‘folds’ (sections).\n",
    "2. Train your model using K-1 folds using the parameter value.\n",
    "3. Test your model on the remaining fold.\n",
    "4. Repeat steps 3 and 4 so that every fold is the test data once.\n",
    "\n",
    "We will run the above steps for different random configurations of parameters to find which parameters minimize our loss. \n",
    "\n",
    "However, we face one further challenge. Since the datasets have 10k-20k examples, it is important that care is taken when estimating the generalization error. If one only uses a single train/test split, it is possible to obtain results that are highly biased to this particular split. To solve this problem, it is common to use an additional outer CV for measuring the generalization error.\n",
    "\n",
    "So to summarise, we will perform **nested cross validations**. We split our data into outer folds and then perform inner CV for each outer fold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner Cross-Validation (Hyper-parameter Tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inner cross-validation loop is responsible for tuning the hyper-parameters of a given model. It is implemented in a parallel, asynchronous manner. As we will see later, we will spawn many processes, each one responsible for evaluating many different hyper-parameter configurations across different folds. The following functions defines the work performed by each of these worker processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(X, y, model, q_in, q_out, cpu=None):\n",
    "    \"\"\" Worker function for evaluating models on cross-validation folds.\n",
    "    \n",
    "    This function should be called by a worker process. The function pulls hyper-parameter\n",
    "    configurations from an input queue, as well as the indices of the training and validation\n",
    "    set. It then trains a model using the hyper-parameter configuration and scores it on the\n",
    "    validation set. The result is then pushed into the output queue. This repeats indefinitely\n",
    "    and the worker process must be terminated from the master.\n",
    "    \n",
    "    The process can be optionally bound to a specific cpu core.\n",
    "    \n",
    "    Args:\n",
    "        X (np.ndarray): Training dataset\n",
    "        y (np.ndarray): Training labels\n",
    "        model (str): Model selection (XGBoost or SnapBoost)\n",
    "        q_in (Queue): Input queue\n",
    "        q_out (Queue): Output queue\n",
    "        cpu (int): CPU on which to bind\n",
    "        \n",
    "    \"\"\"\n",
    "    if cpu is not None:\n",
    "        p = psutil.Process()\n",
    "        p.cpu_affinity([cpu])\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "        os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "    while True:\n",
    "        msg = q_in.get()\n",
    "        X_train = X[msg['train_ind'],:]\n",
    "        y_train = y[msg['train_ind']]\n",
    "        X_test = X[msg['test_ind'], :]\n",
    "        y_test = y[msg['test_ind']]\n",
    "        if model == 'xgb':\n",
    "            msg['score'] = score_xgb(X_train, y_train, X_test, y_test, msg['params'])\n",
    "        else:\n",
    "            msg['score'] = score_snap(X_train, y_train, X_test, y_test, msg['params'])    \n",
    "        q_out.put(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function performs the inner cross-validation for hyper-parameter tuning. It evaluates (in parallel) a given number of random configurations across a number of stratified folds of the training set and identifies the one that gives the minimal validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hpt_parallel(X, y, random_state=42, num_procs = 1, \n",
    "                 num_configs = 100, model='xgb', num_folds=3):\n",
    "    \n",
    "    \"\"\" Parallel, asynchronous cross-validation via random search.\n",
    "    \n",
    "    This function performs stratified cross-validation using a many processes.\n",
    "    Each process is locked to a single CPU core.\n",
    "    \n",
    "    Args:\n",
    "        X (np.ndarray): Training dataset\n",
    "        y (np.ndarray): Training labels\n",
    "        random_state (int): Random state for reproducibility\n",
    "        num_procs (int): Number of proceses to use\n",
    "        num_configs (int): Number of random configurations to draw\n",
    "        model (str): Model selection (XGBoost or SnapBoost)\n",
    "        num_folds (int): Number of cross-validation folds\n",
    "    \n",
    "    Returns:\n",
    "        best_param (dict): Best configuration identified\n",
    "        best_score (float): Validation score for best configuration\n",
    "    \"\"\"\n",
    "    \n",
    "    # create flat list of all possible depth configurations for SnapBoost\n",
    "    depth_limit = 20\n",
    "    depth_configs = []\n",
    "    for i in range(1, depth_limit):\n",
    "        for j in range(i, depth_limit):\n",
    "            depth_configs.append((i,j))\n",
    "\n",
    "    # splitter for creating folds\n",
    "    splitter = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # what is this used for? \n",
    "    # fix random state\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # draw configurations at random\n",
    "    param_list = []\n",
    "    for i in range(0, num_configs):        \n",
    "        num_round = np.random.randint(10, 1000)\n",
    "        max_depth = np.random.randint(1, depth_limit)\n",
    "        learning_rate = 10 ** np.random.uniform(-2.5, -1)\n",
    "        colsample = np.random.uniform(0.5, 1.0)\n",
    "        subsample = np.random.uniform(0.5, 1.0)\n",
    "        lambda_l2 = 10 ** np.random.uniform(-2, 2)\n",
    "\n",
    "        if model == 'xgb':\n",
    "            params = {\n",
    "                'objective': 'binary:logistic',\n",
    "                'num_round': num_round,\n",
    "                'max_depth': max_depth,\n",
    "                'tree_method': 'hist',\n",
    "                'max_bin': 256,\n",
    "                'nthread': 1,\n",
    "                'learning_rate': learning_rate,\n",
    "                'colsample_bytree': colsample,\n",
    "                'subsample': subsample,\n",
    "                'lambda': lambda_l2,\n",
    "                'seed': int(np.random.randint(np.iinfo(np.int32).max))\n",
    "            }\n",
    "        else:\n",
    "        \n",
    "            config = depth_configs[np.random.randint(len(depth_configs))]\n",
    "\n",
    "            params = {\n",
    "                'objective': 'logloss',\n",
    "                'num_round': num_round,\n",
    "                'random_state': int(np.random.randint(np.iinfo(np.int32).max)),\n",
    "                'learning_rate': learning_rate,\n",
    "                'colsample_bytree': colsample,\n",
    "                'subsample': subsample,\n",
    "                'lambda_l2': lambda_l2,\n",
    "                'hist_nbins': 256,\n",
    "                'min_max_depth': config[0],\n",
    "                'max_max_depth': config[1]\n",
    "            }\n",
    "\n",
    "        param_list.append(params)\n",
    "\n",
    "    # create input and output queue\n",
    "    q_in = Queue()\n",
    "    q_out = Queue()\n",
    "\n",
    "    # populate queue for evaluation\n",
    "    for i, (train_ind, test_ind) in enumerate(splitter.split(X, y)):\n",
    "        for j, params in enumerate(param_list):\n",
    "            msg = {\n",
    "                'param_id': j,\n",
    "                'fold_id': i,\n",
    "                'train_ind': train_ind,\n",
    "                'test_ind': test_ind,\n",
    "                'params': params\n",
    "            }\n",
    "            q_in.put(msg)\n",
    "\n",
    "    # create worker processes\n",
    "    procs = []\n",
    "    for p in range(0, num_procs):\n",
    "        procs.append(Process(target=eval, args=(X, y, model, q_in, q_out, p)))\n",
    "\n",
    "    # start workers\n",
    "    for proc in procs:\n",
    "        proc.start()\n",
    "\n",
    "    # collect results from workers\n",
    "    scores = np.zeros(shape=(num_configs, num_folds))\n",
    "    for i in range(0, num_configs*num_folds):\n",
    "        print('Iteration', i, end='\\r')\n",
    "        msg = q_out.get()\n",
    "        param_id = msg['param_id']\n",
    "        fold_id = msg['fold_id']\n",
    "        scores[param_id, fold_id] = msg['score']\n",
    "\n",
    "    # average over folds\n",
    "    scores = np.mean(scores, axis=1)\n",
    "\n",
    "    # identify best configuration\n",
    "    best_param_id = np.argmin(scores)\n",
    "\n",
    "    # terminate worker processes\n",
    "    for proc in procs:\n",
    "        proc.terminate()\n",
    "\n",
    "    return param_list[best_param_id], scores[best_param_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outer Cross-Validation (Generalization Estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to estimate the generalization performance of a tuned model, we also need to use an additional layer of stratified cross-validation. For each outer fold, we perform the inner CV on the training set to identify the optimal parameters. After we have identified the optimal configuration, we need to re-train that configuration on the entirety of the training set, and evaluate it on the corresponding test set. This process is repeated for all outer folds - creating k models, k performances with the generalization performance given as the average across all outer folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function performs the task of re-training the best model found by the inner CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_params(X_train, y_train, X_test, y_test, params, model):\n",
    "    \"\"\" Evaluate the best configuration on a given outer fold.\n",
    "    \n",
    "    This function evaluates a single hyper-parameter configuration of a given model, by \n",
    "    training on a training set and scoring on a test set. The training and evaluation \n",
    "    is performed within a separate process.\n",
    "    \n",
    "    Args:\n",
    "        X_train (np.ndarray): Training dataset\n",
    "        y_train (np.ndarray): Training labels\n",
    "        X_test (np.ndarray): Test dataset\n",
    "        y_test (np.ndarray): Test labels\n",
    "        params (dict): Hyper-parameter configuration\n",
    "        model (str): Model selection (XGBoost or SnapBoost)\n",
    "    \n",
    "    Returns:\n",
    "        score (float): Logistic loss of the trained model evaluated on the test set\n",
    "    \"\"\"\n",
    "    q = Queue()\n",
    "    def p_func(X_train, y_train, X_test, y_test, params, model, q):\n",
    "        if model == 'xgb':\n",
    "            score = score_xgb(X_train, y_train, X_test, y_test, params)\n",
    "        else:\n",
    "            score = score_snap(X_train, y_train, X_test, y_test, params)  \n",
    "        q.put({'score': score})\n",
    "    p = Process(target=p_func, args=(X_train, y_train, X_test, y_test, params, model, q))\n",
    "    p.start()\n",
    "    msg = q.get()\n",
    "    p.join()\n",
    "    return msg['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now come to the main part of the demo, which performs nested CV for the list of Open ML datasets provided and compares the loss achieved by both XGBoost and SnapBoost. If you wish to evalaute a particular data only, a subset of the datasets, or a different set of datasets, simply modify `DATASET_IDS` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment parameters:\n",
    "NUM_OUTER_FOLDS=3 # number of outer folds\n",
    "NUM_INNER_FOLDS=3 # number of inner folds\n",
    "NUM_CONFIGS=100 # number of configurations to try\n",
    "# provide number of cores for our machine ... \n",
    "NUM_PROCS = 40 # number of processes/cores\n",
    "PRINT_PARAMS = True # print off best parameters found\n",
    "\n",
    "# DataFrame for collecting results for all datasets\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# counter to keep track of time\n",
    "t_tot = 0\n",
    "\n",
    "# DATASET_IDS = [dataset]\n",
    "name = dataset.name \n",
    "\n",
    "# random state \n",
    "seed = dataset_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Starting nested CV on dataset: ailerons\n",
      "Best parameters for model xgb on outer fold 0:\n",
      "{\n",
      "    \"objective\": \"binary:logistic\",\n",
      "    \"num_round\": 531,\n",
      "    \"max_depth\": 5,\n",
      "    \"tree_method\": \"hist\",\n",
      "    \"max_bin\": 256,\n",
      "    \"nthread\": 1,\n",
      "    \"learning_rate\": 0.030576966439305724,\n",
      "    \"colsample_bytree\": 0.7157460227581843,\n",
      "    \"subsample\": 0.9569441240285168,\n",
      "    \"lambda\": 2.214122307473504,\n",
      "    \"seed\": 694466545\n",
      "}\n",
      "Best parameters for model snap on outer fold 0:\n",
      "{\n",
      "    \"objective\": \"logloss\",\n",
      "    \"num_round\": 495,\n",
      "    \"random_state\": 1640255808,\n",
      "    \"learning_rate\": 0.023748091051762912,\n",
      "    \"colsample_bytree\": 0.7527176254754524,\n",
      "    \"subsample\": 0.5901700545531336,\n",
      "    \"lambda_l2\": 1.241457692562928,\n",
      "    \"hist_nbins\": 256,\n",
      "    \"min_max_depth\": 1,\n",
      "    \"max_max_depth\": 6\n",
      "}\n",
      "Iteration 0\r"
     ]
    }
   ],
   "source": [
    "# create statified kfold spliter\n",
    "splitter = StratifiedKFold(n_splits=NUM_OUTER_FOLDS, shuffle=True, random_state=seed)\n",
    "\n",
    "# start nested CV\n",
    "t0 = time.time()\n",
    "print(\">> Starting nested CV on dataset: %s\" % (name))\n",
    "\n",
    "# DataFrame for collecting results for this dataset\n",
    "this_df = pd.DataFrame()\n",
    "\n",
    "# Outer Loop: outer cross validation \n",
    "for fold, (train_ind, test_ind) in enumerate(splitter.split(X, y)):\n",
    "\n",
    "    # results for this dataset, containing fold\n",
    "    res = pd.Series(name=fold, dtype=np.float64)\n",
    "\n",
    "    # create train/test split for this outer fold\n",
    "    X_train, X_test = X[train_ind, :], X[test_ind, :]\n",
    "    y_train, y_test = y[train_ind], y[test_ind]\n",
    "\n",
    "    # loop over both models\n",
    "    for model in ['xgb','snap']:\n",
    "\n",
    "    # Inner Loop: perform inner CV for this outer fold\n",
    "        opt_params, res[\"val_%s\" % (model)] = hpt_parallel(X_train, y_train, \n",
    "                                                           random_state=seed,\n",
    "                                                           num_procs=NUM_PROCS, \n",
    "                                                           num_configs=NUM_CONFIGS, \n",
    "                                                           model=model, \n",
    "                                                           num_folds=NUM_INNER_FOLDS)\n",
    "\n",
    "        # optionally print off the best configuration found\n",
    "        if PRINT_PARAMS:\n",
    "            print(\"Best parameters for model %s on outer fold %d:\" % (model, fold))\n",
    "            print(json.dumps(opt_params, indent=4))\n",
    "\n",
    "        # re-train the best configuration on the train set and evaluate on the test set\n",
    "        res[\"test_%s\" % (model)] = eval_params(X_train, y_train, \n",
    "                                               X_test, y_test, \n",
    "                                               params=opt_params, \n",
    "                                               model=model)\n",
    "        \n",
    "        # store results for this fold\n",
    "    this_df = this_df.append(res)\n",
    "    \n",
    "t_elap = time.time() - t0\n",
    "t_tot += t_elap\n",
    "print(\">> Finished nested CV on dataset %s in %d seconds\" % (name, t_elap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_res = this_df.mean()\n",
    "this_res['name'] = dataset.name\n",
    "df = this_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loss_gain = 100*((df['val_xgb']-df['val_snap'])/df['val_xgb'])\n",
    "# test_loss_gain = 100*((df['test_xgb']-df['test_snap'])/df['test_xgb'])\n",
    "\n",
    "max_val = max(df['val_xgb'], df['val_snap'])\n",
    "min_val = min(df['val_xgb'], df['val_snap'])\n",
    "\n",
    "max_test = max(df['test_xgb'], df['test_snap'])\n",
    "min_test = min(df['test_xgb'], df['test_snap'])\n",
    "\n",
    "val_loss_gain = 100*((max_val-min_val)/max_val)\n",
    "test_loss_gain = 100*((max_test-min_test)/max_test)\n",
    "\n",
    "# for whichever value is larger \n",
    "\n",
    "if (df['val_xgb'] > df['val_snap']): \n",
    "    val_outperformer = \"SnapBoost\"\n",
    "else: \n",
    "    val_outperformer = \"XGBoost\"\n",
    "\n",
    "if (df['test_xgb'] > df['test_snap']): \n",
    "    test_outperformer = \"SnapBoost\"\n",
    "else: \n",
    "    test_outperformer = \"XGBoost\"\n",
    "    \n",
    "print(\"For the \" + dataset.name + \" dataset we see \" + val_outperformer + \" outperforms on the validation set providing a \" + str(val_loss_gain) + \"% improvement in validation loss.\")\n",
    "print(\"For the \" + dataset.name + \" dataset we see \" + test_outperformer + \" outperforms on the test set providing a \" + str(test_loss_gain) + \"% improvement in generalization loss.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
